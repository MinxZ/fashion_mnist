{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.applications import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import *\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from skimage.transform import resize\n",
    "\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    num_classes = 10\n",
    "    height,width = 128, 128\n",
    "        \n",
    "    (train, train_l), (test, test_l) = fashion_mnist.load_data()\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y = keras.utils.to_categorical(train_l, num_classes)\n",
    "    y_test = keras.utils.to_categorical(test_l, num_classes)\n",
    "    \n",
    "    \n",
    "    # use this in future\n",
    "    # X_train = np.array([resize(x, (height,width)).astype(float) for x in tqdm(iter(X_train.astype(int)))])/255.\n",
    "    \n",
    "    train = train.reshape((-1,28,28))\n",
    "    train = np.array([misc.imresize(x, (height,width)) for x in tqdm(iter(train))])\n",
    "    test = test.reshape((-1,28,28))\n",
    "    test = np.array([misc.imresize(x, (height,width)) for x in tqdm(iter(test))])\n",
    "\n",
    "    x = np.stack((train, train, train), axis=3)\n",
    "    x_test = np.stack((test, test, test), axis=3)\n",
    "\n",
    "    # devide into train and validation \n",
    "    dvi = int(train.shape[0] * 0.9)\n",
    "    x_train = x[:dvi, :, :, :]\n",
    "    y_train = y[:dvi, :]\n",
    "    x_val = x[dvi:, :, :, :]\n",
    "    y_val = y[dvi:, :]\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_val.shape[0], 'validation samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  app.launch_new_instance()\n",
      "60000it [00:06, 9818.39it/s]\n",
      "0it [00:00, ?it/s]/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "10000it [00:00, 10220.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (54000, 128, 128, 3)\n",
      "54000 train samples\n",
      "6000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(model_name, lr, optimizer, epoch, patience, batch_size):\n",
    "    # Compute the bottleneck feature\n",
    "    \n",
    "    n_class = y_test.shape[1]\n",
    "    input_shape = x_train.shape[1:]\n",
    "    weights='imagenet'\n",
    "    print(' weights are ' + str(weights))\n",
    "\n",
    "    def get_features(MODEL, data=x_train):\n",
    "        cnn_model = MODEL(\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            weights=weights)\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "        x = inputs\n",
    "        x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "        x = cnn_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        cnn_model = Model(inputs, x)\n",
    "\n",
    "        features = cnn_model.predict(data, batch_size=32, verbose=1)\n",
    "        return features\n",
    "\n",
    "    def fine_tune(MODEL,\n",
    "                  model_name,\n",
    "                  optimizer,\n",
    "                  lr,\n",
    "                  epoch,\n",
    "                  patience,\n",
    "                  batch_size,\n",
    "                  X=x_train):\n",
    "        # Fine-tune the model\n",
    "        print(\"\\n\\n Fine tune \" + model_name + \":\")\n",
    "        \n",
    "        if weights == None:\n",
    "            try:\n",
    "                model.load_weights(model_name + '.h5')\n",
    "                print('Load ' + model_name + '.h5 successfully.')\n",
    "            except:\n",
    "                try:\n",
    "                    model.load_weights('fc_' + model_name + '.h5', by_name=True)\n",
    "                    print('Fail to load ' + model_name + '.h5, load fc_' +\n",
    "                          model_name + '.h5 instead.')\n",
    "                except:\n",
    "                    print('Start computing ' + model_name +\n",
    "                          ' bottleneck feature: ')\n",
    "                    features = get_features(MODEL, X)\n",
    "\n",
    "                    # Training models\n",
    "                    inputs = Input(features.shape[1:])\n",
    "                    x = inputs\n",
    "                    x = Dropout(0.5)(x)\n",
    "                    x = Dense(\n",
    "                        n_class, activation='softmax', name='predictions')(x)\n",
    "                    model_fc = Model(inputs, x)\n",
    "                    model_fc.compile(\n",
    "                        optimizer='adam',\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "                    h = model_fc.fit(\n",
    "                        features,\n",
    "                        y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs=5,\n",
    "                        validation_split=0.1)\n",
    "\n",
    "                    model_fc.save('fc_' + model_name + '.h5')\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            horizontal_flip=True)\n",
    "#         ,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input)\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "        x = inputs\n",
    "        cnn_model = MODEL(\n",
    "            include_top=False, input_shape=input_shape, weights=weights)\n",
    "        x = cnn_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(n_class, activation='softmax', name='predictions')(x)\n",
    "        model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "        # for layer in model.layers[:114]:\n",
    "        #     layer.trainable = False\n",
    "   \n",
    "        print(\"\\n \" + \"Optimizer=\" + optimizer + \" lr=\" + str(lr) + \" \\n\")\n",
    "        \n",
    "        if optimizer == \"Adam\":\n",
    "            model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "        elif optimizer == \"SGD\":\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=SGD(lr=lr, momentum=0.9, nesterov=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "        class LossHistory(keras.callbacks.Callback):\n",
    "            def on_train_begin(self, logs={}):\n",
    "                # self.val_losses = []\n",
    "                self.losses = []\n",
    "\n",
    "            def on_epoch_end(self, batch, logs={}):\n",
    "                # self.val_losses.append(logs.get(\"val_loss\"))\n",
    "                self.losses.append((logs.get('loss'), logs.get(\"val_loss\")))\n",
    "        \n",
    "#         model.summary()\n",
    "        history = LossHistory()\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "        checkpointer = ModelCheckpoint(\n",
    "            filepath=model_name + '.h5', verbose=0, save_best_only=True)\n",
    "        h2 = model.fit_generator(\n",
    "            datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "            steps_per_epoch=len(x_train) / batch_size,\n",
    "            validation_data=val_datagen.flow(\n",
    "                x_val, y_val, batch_size=batch_size),\n",
    "            validation_steps=len(x_val) / batch_size,\n",
    "            epochs=epoch,\n",
    "            callbacks=[early_stopping, checkpointer, history])\n",
    "        \n",
    "        with open(model_name + \".csv\", 'a') as f_handle:\n",
    "            np.savetxt(f_handle, history.losses)\n",
    "        \n",
    "    list_model = {\n",
    "        \"Xception\": Xception,\n",
    "        \"InceptionV3\": InceptionV3,\n",
    "        \"InceptionResNetV2\": InceptionResNetV2,\n",
    "        \"VGG16\": VGG16,\n",
    "        \"MobileNet\": MobileNet\n",
    "    }\n",
    "    fine_tune(list_model[model_name], model_name, optimizer, lr, epoch,\n",
    "              patience, batch_size, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " weights are imagenet\n",
      "\n",
      "\n",
      " Fine tune MobileNet:\n",
      "\n",
      " Optimizer=Adam lr=0.01 \n",
      "\n",
      "Epoch 1/10000\n",
      "844/843 [==============================] - 209s 248ms/step - loss: 0.3428 - acc: 0.8873 - val_loss: 0.2497 - val_acc: 0.9127\n",
      "Epoch 2/10000\n",
      "156/843 [====>.........................] - ETA: 2:41 - loss: 0.2154 - acc: 0.9229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 451, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python2.7/genericpath.py\", line 26, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "run(\"MobileNet\", 1e-2, \"Adam\", 10000, 5, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
