{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.applications import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import *\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import *\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from scipy import misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    num_classes = 10\n",
    "    (train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    train = train.reshape((train.shape[0],28,28,1))\n",
    "    x_test = x_test.reshape((x_test.shape[0],28,28,1))\n",
    "\n",
    "    # devide into train and validation sets\n",
    "    dvi = int(train.shape[0] * 0.9)\n",
    "    x_train = train[:dvi, :, :, :]\n",
    "    y_train = y_train[:dvi]\n",
    "    x_val = train[dvi:, :, :, :]\n",
    "    y_val = y_train[dvi:]\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_val /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_val.shape[0], 'validation samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape, MODEL):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = input\n",
    "    cnn_model = MODEL(\n",
    "        include_top=False, input_shape=input_shape, weights=None)\n",
    "    x = cnn_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu', name='sim')(x)\n",
    "    model = Model(input, outputs=x)\n",
    "    model.load_weights(model_name + '.h5', by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (54000, 28, 28, 1)\n",
      "54000 train samples\n",
      "6000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data()\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_shape, MobileNet)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_network.summary()\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107320 samples, validate on 19980 samples\n",
      "Epoch 1/200\n",
      "107320/107320 [==============================] - 60s 563us/step - loss: 0.3137 - accuracy: 0.7402 - val_loss: 0.1345 - val_accuracy: 0.8327\n",
      "Epoch 2/200\n",
      "107320/107320 [==============================] - 55s 514us/step - loss: 0.1176 - accuracy: 0.8470 - val_loss: 0.1279 - val_accuracy: 0.8320\n",
      "Epoch 3/200\n",
      "107320/107320 [==============================] - 55s 514us/step - loss: 0.1018 - accuracy: 0.8679 - val_loss: 0.0927 - val_accuracy: 0.8766\n",
      "Epoch 4/200\n",
      "107320/107320 [==============================] - 55s 514us/step - loss: 0.1081 - accuracy: 0.8622 - val_loss: 0.1058 - val_accuracy: 0.8670\n",
      "Epoch 5/200\n",
      "107320/107320 [==============================] - 55s 516us/step - loss: 0.0948 - accuracy: 0.8804 - val_loss: 0.0880 - val_accuracy: 0.8896\n",
      "Epoch 6/200\n",
      "107320/107320 [==============================] - 55s 516us/step - loss: 0.0830 - accuracy: 0.8970 - val_loss: 0.0855 - val_accuracy: 0.8917\n",
      "Epoch 7/200\n",
      "107320/107320 [==============================] - 55s 516us/step - loss: 0.0713 - accuracy: 0.9092 - val_loss: 0.0680 - val_accuracy: 0.9113\n",
      "Epoch 8/200\n",
      "107320/107320 [==============================] - 55s 516us/step - loss: 0.0630 - accuracy: 0.9202 - val_loss: 0.0630 - val_accuracy: 0.9156\n",
      "Epoch 9/200\n",
      "107320/107320 [==============================] - 55s 515us/step - loss: 0.0598 - accuracy: 0.9239 - val_loss: 0.0673 - val_accuracy: 0.9109\n",
      "Epoch 10/200\n",
      "107320/107320 [==============================] - 55s 516us/step - loss: 0.0571 - accuracy: 0.9284 - val_loss: 0.0618 - val_accuracy: 0.9198\n",
      "Epoch 11/200\n",
      " 67200/107320 [=================>............] - ETA: 19s - loss: 0.0541 - accuracy: 0.9322"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 200\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "patience = 5\n",
    "model_name = 'MobileNet'\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # self.val_losses = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        # self.val_losses.append(logs.get(\"val_loss\"))\n",
    "        self.losses.append((logs.get('loss'), logs.get(\"val_loss\")))\n",
    "history = LossHistory()\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=patience, verbose=2, mode='auto')\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_name + '_sim.h5', verbose=0, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.3, patience=3)\n",
    "\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y),\n",
    "          callbacks=[history, early_stopping, checkpointer, reduce_lr])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
