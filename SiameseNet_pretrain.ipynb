{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.applications import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import *\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import *\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from scipy import misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(height=128, width=128, use_imagenet=None):\n",
    "    num_classes = 10    \n",
    "    (train, train_l), (test, test_l) = fashion_mnist.load_data()\n",
    "\n",
    "    y = keras.utils.to_categorical(train_l, num_classes)\n",
    "    y_test = keras.utils.to_categorical(test_l, num_classes)\n",
    "    \n",
    "    if use_imagenet:\n",
    "        train = (train.reshape((-1,28,28))/255. - 0.5)*2\n",
    "        train = np.array([misc.imresize(x, (height,width)) for x in tqdm(iter(train))])\n",
    "        test = (test.reshape((-1,28,28))/255. - 0.5)*2\n",
    "        test = np.array([misc.imresize(x, (height,width)) for x in tqdm(iter(test))])\n",
    "\n",
    "        x = np.stack((train, train, train), axis=3)\n",
    "        x_test = np.stack((test, test, test), axis=3)\n",
    "    else:\n",
    "        x = (train.reshape((train.shape[0],28,28,1))/255. - 0.5)*2\n",
    "        x_test = (test.reshape((test.shape[0],28,28,1))/255. -0.5)*2\n",
    "\n",
    "    # devide into train and validation \n",
    "    dvi = int(train.shape[0] * 0.9)\n",
    "    x_train = x[:dvi, :, :, :]\n",
    "    y_train = y[:dvi, :]\n",
    "    x_val = x[dvi:, :, :, :]\n",
    "    y_val = y[dvi:, :]\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_val.shape[0], 'validation samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (54000, 28, 28, 1)\n",
      "54000 train samples\n",
      "6000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_name, lr, optimizer, epoch, patience, batch_size, weights, test=None):\n",
    "    n_class = y_test.shape[1]\n",
    "    input_shape = x_train.shape[1:]\n",
    "    \n",
    "    if weights == 'None':\n",
    "        weights = None\n",
    "        print(\"\\n Training on \" + model_name + \": \\n\")\n",
    "    else:\n",
    "        weights = 'imagenet'\n",
    "        print(\"\\n Fine tune on \" + model_name + \": \\n\")\n",
    "        \n",
    "    print('Weights are ' + str(weights))\n",
    "\n",
    "    def get_features(MODEL, data=x_train):\n",
    "        cnn_model = MODEL(\n",
    "            include_top=False, input_shape=input_shape, weights=weights)\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "        x = inputs\n",
    "        x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "        x = cnn_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        cnn_model = Model(inputs, x)\n",
    "\n",
    "        features = cnn_model.predict(data, batch_size=32, verbose=1)\n",
    "        return features\n",
    "\n",
    "    def fine_tune(MODEL,\n",
    "                  model_name,\n",
    "                  optimizer,\n",
    "                  lr,\n",
    "                  epoch,\n",
    "                  patience,\n",
    "                  batch_size,\n",
    "                  weights,\n",
    "                  X=x_train,\n",
    "                  test=None):\n",
    "        # Fine-tune the model\n",
    "\n",
    "        from random_eraser import get_random_eraser\n",
    "        datagen = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=get_random_eraser(v_h=60, pixel_level=True))\n",
    "\n",
    "        val_datagen = ImageDataGenerator()\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "        x = inputs\n",
    "        cnn_model = MODEL(\n",
    "            include_top=False, input_shape=input_shape, weights=None)\n",
    "        x = cnn_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu', name='sim')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(n_class, activation='softmax', name='predictions')(x)\n",
    "        model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "        # Loading weights\n",
    "        try:\n",
    "            model.load_weights(model_name + '.h5')\n",
    "            print('Load ' + model_name + '.h5 successfully.')\n",
    "        except:\n",
    "            if weights == 'imagenet':\n",
    "                print('Start computing ' + model_name +\n",
    "                      ' bottleneck feature: ')\n",
    "                features = get_features(MODEL, X)\n",
    "\n",
    "                # Training models\n",
    "                inputs = Input(features.shape[1:])\n",
    "                x = inputs\n",
    "                x = Dropout(0.5)(x)\n",
    "                x = Dense(128, activation='relu', name='sim')(x)\n",
    "                x = Dropout(0.5)(x)                \n",
    "                x = Dense(\n",
    "                    n_class, activation='softmax', name='predictions')(x)\n",
    "                model_fc = Model(inputs, x)\n",
    "                model_fc.compile(\n",
    "                    optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                h = model_fc.fit(\n",
    "                    features,\n",
    "                    y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.1)\n",
    "                model_fc.save('fc_' + model_name + '.h5')\n",
    "                model.load_weights(\n",
    "                    'fc_' + model_name + '.h5', by_name=True)\n",
    "\n",
    "\n",
    "        print(\"Optimizer=\" + optimizer + \" lr=\" + str(lr) + \" \\n\")\n",
    "        if optimizer == \"Adam\":\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "        elif optimizer == \"SGD\":\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=SGD(lr=lr, momentum=0.9, nesterov=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "        if not test:\n",
    "            datagen.fit(x_train)\n",
    "            val_datagen.fit(x_val)\n",
    "            class LossHistory(keras.callbacks.Callback):\n",
    "                def on_train_begin(self, logs={}):\n",
    "                    self.losses = []\n",
    "                def on_epoch_end(self, batch, logs={}):\n",
    "                    self.losses.append((logs.get('loss'), logs.get(\"val_loss\")))\n",
    "\n",
    "            history = LossHistory()\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "            checkpointer = ModelCheckpoint(\n",
    "                filepath=model_name + '.h5', verbose=0, save_best_only=True)\n",
    "            reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3, verbose=1)\n",
    "            if optimizer == \"Adam\":\n",
    "                callbacks=[history, early_stopping, checkpointer]\n",
    "            else:\n",
    "                callbacks=[history, early_stopping, checkpointer, reduce_lr]\n",
    "            h = model.fit_generator(\n",
    "                datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                steps_per_epoch=len(x_train) / batch_size,\n",
    "                validation_data=val_datagen.flow(\n",
    "                    x_val, y_val, batch_size=batch_size),\n",
    "                validation_steps=len(x_val) / batch_size,\n",
    "                epochs=epoch,\n",
    "                callbacks=callbacks)\n",
    "            return h\n",
    "        else:\n",
    "            print('Evalute on test set')\n",
    "            val_datagen.fit(x_test)\n",
    "            score = model.evaluate_generator(val_datagen.flow(x_test, y_test, batch_size=batch_size),\n",
    "                len(x_test) / batch_size)\n",
    "            print(score)\n",
    "            return score\n",
    "            \n",
    "\n",
    "    list_model = {\n",
    "        \"Xception\": Xception,\n",
    "        \"InceptionV3\": InceptionV3,\n",
    "        \"InceptionResNetV2\": InceptionResNetV2,\n",
    "        \"VGG16\": VGG16,\n",
    "        \"MobileNet\": MobileNet\n",
    "    }\n",
    "    fine_tune(list_model[model_name], model_name, optimizer, lr, epoch,\n",
    "              patience, batch_size, weights, x_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = run(\"MobileNet\", 1e-2, \"Adam\", 10000, 5, 128, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training on MobileNet: \n",
      "\n",
      "Weights are None\n",
      "Load MobileNet.h5 successfully.\n",
      "Optimizer=SGD lr=0.0001 \n",
      "\n",
      "Epoch 1/10000\n",
      "422/421 [==============================] - 17s 41ms/step - loss: 0.1683 - acc: 0.9412 - val_loss: 0.1919 - val_acc: 0.9313\n",
      "Epoch 2/10000\n",
      "422/421 [==============================] - 15s 35ms/step - loss: 0.1661 - acc: 0.9417 - val_loss: 0.1925 - val_acc: 0.9312\n",
      "Epoch 3/10000\n",
      "422/421 [==============================] - 15s 35ms/step - loss: 0.1634 - acc: 0.9414 - val_loss: 0.1931 - val_acc: 0.9305\n",
      "Epoch 4/10000\n",
      "422/421 [==============================] - 15s 35ms/step - loss: 0.1627 - acc: 0.9434 - val_loss: 0.1934 - val_acc: 0.9308\n",
      "Epoch 5/10000\n",
      "383/421 [==========================>...] - ETA: 1s - loss: 0.1610 - acc: 0.9433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h2 = run(\"MobileNet\", 1e-5, \"SGD\", 10000, 6, 128, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training on MobileNet: \n",
      "\n",
      "Weights are None\n",
      "Load MobileNet.h5 successfully.\n",
      "Optimizer=SGD lr=0.0005 \n",
      "\n",
      "Evalute on test set\n",
      "[0.20429442639350892, 0.92749999999999999]\n"
     ]
    }
   ],
   "source": [
    "score = run(\"MobileNet\", 5e-4, \"SGD\", 10000, 5, 128, 'None', 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
